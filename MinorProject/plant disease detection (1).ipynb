{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    " #Define the path to the zipped dataset\n",
    "zip_path = r'C:\\Users\\FAISAL\\Downloads\\plantdiseasedetection.zip'\n",
    "\n",
    "#Define extraction path\n",
    "extract_path = r'C:\\Users\\FAISAL\\Machine_learning\\myproject'\n",
    "\n",
    " #Unzip the file\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "print(\"Dataset extracted to:\", extract_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5Re2yEvJttZ"
   },
   "source": [
    "# **Performing EDA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZObyYF8eM7ye"
   },
   "source": [
    "# 1. load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 450,
     "status": "ok",
     "timestamp": 1735491984655,
     "user": {
      "displayName": "Faisal Yousuf",
      "userId": "02177083131466506578"
     },
     "user_tz": -330
    },
    "id": "s57Cn2C4J1w3",
    "outputId": "6cdb8124-5e57-4be8-d389-231d4d660ffa"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Path to your dataset\n",
    "train_path= r'C:\\Users\\FAISAL\\Machine_learning\\myproject\\New Plant Diseases Dataset(Augmented)\\New Plant Diseases Dataset(Augmented)\\train'\n",
    "valid_path= r'C:\\Users\\FAISAL\\Machine_learning\\myproject\\New Plant Diseases Dataset(Augmented)\\New Plant Diseases Dataset(Augmented)\\valid'\n",
    "\n",
    "# List all subdirectories (representing different categories or classes)\n",
    "subdirs_train = os.listdir(train_path)\n",
    "subdirs_valid = os.listdir(valid_path)\n",
    "\n",
    "print(\"categories in train directory:\", subdirs_train)\n",
    "print(\"Total categories in train directory\",len(subdirs_train))\n",
    "print(\"\\n\")\n",
    "print(\"categories in valid directory:\", subdirs_valid)\n",
    "print(\"Total categories in valid directory\",len(subdirs_valid))\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"categories in train directory and number of images in it\")\n",
    "total_train_images = 0\n",
    "for subdir in subdirs_train:\n",
    "    dir_path = os.path.join(train_path, subdir)\n",
    "    num_files = len(os.listdir(dir_path))\n",
    "    total_train_images += num_files\n",
    "    print(f\"{subdir}: {num_files} images\")\n",
    "print(\"Total images in train directory:\", total_train_images)\n",
    "print(\"\\n\")\n",
    "print(\"categories in valid directory and number of images in it\")\n",
    "total_valid_images = 0\n",
    "for subdir in subdirs_valid:\n",
    "    dir_path = os.path.join(valid_path, subdir)\n",
    "    num_files = len(os.listdir(dir_path))\n",
    "    total_valid_images += num_files\n",
    "    print(f\"{subdir}: {num_files} images\")\n",
    "print(\"Total images in valid directory:\", total_valid_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B3ojR9d-TI0p"
   },
   "source": [
    "✅**WE GOT DATASET IS DIVIDED INTO 80/20 RATIO AND DATASET IS DIVIDED INTO TRAIN AND VALIDATION DIRECTORIES ALREADY**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tsly430fS7FU"
   },
   "source": [
    "# 2. CHECK FOR CLASS DISTRIBUTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 662
    },
    "executionInfo": {
     "elapsed": 5507,
     "status": "ok",
     "timestamp": 1735492008483,
     "user": {
      "displayName": "Faisal Yousuf",
      "userId": "02177083131466506578"
     },
     "user_tz": -330
    },
    "id": "OPj7dSpxTCO-",
    "outputId": "2d8dd410-24d4-41bd-abd0-abac3ea35ebd"
   },
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Count the number of images per class in the training set\n",
    "train_class_counts = {subdir: len(os.listdir(os.path.join(train_path, subdir))) for subdir in os.listdir(train_path)}\n",
    "print(\"Training set class distribution:\", train_class_counts)\n",
    "\n",
    "# Count the number of images per class in the validation set\n",
    "val_class_counts = {subdir: len(os.listdir(os.path.join(valid_path, subdir))) for subdir in os.listdir(valid_path)}\n",
    "print(\"Validation set class distribution:\", val_class_counts)\n",
    "\n",
    "# Plot the class distribution for the training set\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)  # (row, column, position)\n",
    "sns.barplot(x=list(train_class_counts.keys()), y=list(train_class_counts.values()))\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Training Set Class Distribution')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Images')\n",
    "\n",
    "# Plot the class distribution for the validation set\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.barplot(x=list(val_class_counts.keys()), y=list(val_class_counts.values()))\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Validation Set Class Distribution')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Images')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCFsrB6KWqkJ"
   },
   "source": [
    "✅***DATASET IS BALANCED***\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4qmtMY__W5Wj"
   },
   "source": [
    "# 3. PREVIEW SOME IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 810
    },
    "executionInfo": {
     "elapsed": 4228,
     "status": "ok",
     "timestamp": 1735492020039,
     "user": {
      "displayName": "Faisal Yousuf",
      "userId": "02177083131466506578"
     },
     "user_tz": -330
    },
    "id": "t6hr8wEOXxOC",
    "outputId": "6f49df2f-d960-4a20-d115-eb75595b77dc"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Preview some random images from each class\n",
    "num_images = 6  # Number of random images to preview\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))  # Create a 2x3 grid for the images\n",
    "\n",
    "# Flatten the axes array for easier iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Track which index to use for the next subplot\n",
    "index = 0\n",
    "\n",
    "# Loop through subdirectories (classes) and pick random images\n",
    "for subdir in subdirs_train:\n",
    "    dir_path = os.path.join(train_path, subdir)\n",
    "    img_files = os.listdir(dir_path)\n",
    "\n",
    "    # Pick a random image from the class\n",
    "    random_image = random.choice(img_files)\n",
    "    img_path = os.path.join(dir_path, random_image)\n",
    "    img = mpimg.imread(img_path)\n",
    "\n",
    "    # Display the image in the corresponding subplot\n",
    "    axes[index].imshow(img)\n",
    "    axes[index].set_title(f\"Class: {subdir}\")\n",
    "    axes[index].axis('off')  # Hide axes\n",
    "    index += 1\n",
    "\n",
    "    # Stop once we have displayed the required number of images\n",
    "    if index >= num_images:\n",
    "        break\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EIj7aj4KZ0Wo"
   },
   "source": [
    "# 4. IMAGE SIZE AND RESOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53346,
     "status": "ok",
     "timestamp": 1735492084893,
     "user": {
      "displayName": "Faisal Yousuf",
      "userId": "02177083131466506578"
     },
     "user_tz": -330
    },
    "id": "NugzUQznaDkL",
    "outputId": "2c19f0db-0f20-42f5-8852-a788e392b0d5"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Assume you want to check all images in the dataset (train set)\n",
    "all_sizes_are_same = True\n",
    "all_formats_are_same = True\n",
    "expected_size = None  # To store the first image's size for comparison\n",
    "expected_format = None  # To store the first image's format for comparison\n",
    "\n",
    "# Check the size and format of all images\n",
    "for subdir in subdirs_train:\n",
    "    dir_path = os.path.join(train_path, subdir)\n",
    "    img_files = os.listdir(dir_path)\n",
    "\n",
    "    for img_file in img_files:\n",
    "        img_path = os.path.join(dir_path, img_file)\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        # Get the size and format of the current image\n",
    "        img_size = img.size\n",
    "        img_format = img.format\n",
    "\n",
    "        # Set the expected size and format for the first image\n",
    "        if expected_size is None:\n",
    "            expected_size = img_size\n",
    "        if expected_format is None:\n",
    "            expected_format = img_format\n",
    "\n",
    "        # Check if the current image size matches the expected size\n",
    "        if img_size != expected_size:\n",
    "            all_sizes_are_same = False\n",
    "            print(f\"Image {img_file} in class {subdir} has size {img_size} which is different from expected size {expected_size}\")\n",
    "\n",
    "        # Check if the current image format matches the expected format\n",
    "        if img_format != expected_format:\n",
    "            all_formats_are_same = False\n",
    "            print(f\"Image {img_file} in class {subdir} has format {img_format} which is different from expected format {expected_format}\")\n",
    "\n",
    "# Print the final result\n",
    "if all_sizes_are_same:\n",
    "    print(\"All images are of the same size in training set.\",expected_size)\n",
    "else:\n",
    "    print(\"Some images have different sizes in taining set.\")\n",
    "\n",
    "if all_formats_are_same:\n",
    "    print(\"All images are of the same format in training set.\",expected_format)\n",
    "else:\n",
    "    print(\"Some images have different formats in training set.\")\n",
    "\n",
    "\n",
    "\n",
    "# Assume you want to check all images in the dataset (validation sets)\n",
    "all_sizes_are_same = True\n",
    "all_formats_are_same = True\n",
    "expected_size = None  # To store the first image's size for comparison\n",
    "expected_format = None  # To store the first image's format for comparison\n",
    "\n",
    "# Check the size and format of all images\n",
    "for subdir in subdirs_valid:\n",
    "    dir_path = os.path.join(valid_path, subdir)\n",
    "    img_files = os.listdir(dir_path)\n",
    "\n",
    "    for img_file in img_files:\n",
    "        img_path = os.path.join(dir_path, img_file)\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        # Get the size and format of the current image\n",
    "        img_size = img.size\n",
    "        img_format = img.format\n",
    "\n",
    "        # Set the expected size and format for the first image\n",
    "        if expected_size is None:\n",
    "            expected_size = img_size\n",
    "        if expected_format is None:\n",
    "            expected_format = img_format\n",
    "\n",
    "        # Check if the current image size matches the expected size\n",
    "        if img_size != expected_size:\n",
    "            all_sizes_are_same = False\n",
    "            print(f\"Image {img_file} in class {subdir} has size {img_size} which is different from expected size {expected_size}\")\n",
    "\n",
    "        # Check if the current image format matches the expected format\n",
    "        if img_format != expected_format:\n",
    "            all_formats_are_same = False\n",
    "            print(f\"Image {img_file} in class {subdir} has format {img_format} which is different from expected format {expected_format}\")\n",
    "\n",
    "# Print the final result\n",
    "if all_sizes_are_same:\n",
    "    print(\"All images are of the same size in validation set.\",expected_size)\n",
    "else:\n",
    "    print(\"Some images have different sizes in validation set.\")\n",
    "\n",
    "if all_formats_are_same:\n",
    "    print(\"All images are of the same format in validation set.\",expected_format)\n",
    "else:\n",
    "    print(\"Some images have different formats in validation set.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xE7j7-zRcPiT"
   },
   "source": [
    "**✅ ALL IMAGES ARE OF SAME SIZE (256,256) AND OF SAME FORMAT JPEG**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OHiw_Bt8ej1P"
   },
   "source": [
    "# 5. CHECK FOR MISSING DATA OR CORRUPTED FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11779,
     "status": "ok",
     "timestamp": 1735492101080,
     "user": {
      "displayName": "Faisal Yousuf",
      "userId": "02177083131466506578"
     },
     "user_tz": -330
    },
    "id": "dh-mGVQIeqkC",
    "outputId": "f11100b9-6ce2-41cd-b184-4bf1eed12e01"
   },
   "outputs": [],
   "source": [
    "# Check for any corrupted or unreadable image files in training set\n",
    "corrupt_files = []\n",
    "for subdir in subdirs_train:\n",
    "    dir_path = os.path.join(train_path, subdir)\n",
    "    img_files = os.listdir(dir_path)\n",
    "    for img_file in img_files:\n",
    "        img_path = os.path.join(dir_path, img_file)\n",
    "        try:\n",
    "            img = Image.open(img_path)\n",
    "            img.verify()  # Verify image integrity\n",
    "        except (IOError, SyntaxError) as e:\n",
    "            corrupt_files.append(img_path)\n",
    "\n",
    "if corrupt_files:\n",
    "    print(f\"Corrupted files found in training set: {corrupt_files}\")\n",
    "else:\n",
    "    print(\"No corrupted files found in training set.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Check for any corrupted or unreadable image files in validation set\n",
    "corrupt_files = []\n",
    "for subdir in subdirs_valid:\n",
    "    dir_path = os.path.join(valid_path, subdir)\n",
    "    img_files = os.listdir(dir_path)\n",
    "    for img_file in img_files:\n",
    "        img_path = os.path.join(dir_path, img_file)\n",
    "        try:\n",
    "            img = Image.open(img_path)\n",
    "            img.verify()  # Verify image integrity\n",
    "        except (IOError, SyntaxError) as e:\n",
    "            corrupt_files.append(img_path)\n",
    "\n",
    "if corrupt_files:\n",
    "    print(f\"Corrupted files found in validation set: {corrupt_files}\")\n",
    "else:\n",
    "    print(\"No corrupted files found in validation set.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sO1NgZ9dgViD"
   },
   "source": [
    "✅**ALL IMAGES ARE ACCESSIBLE AND GOOD**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VoCOWTXxiOyg"
   },
   "source": [
    "# 6. AUGMENTATION\n",
    "     ✅**SINCE THIS DATASET IS ALREADY OFFLINE AUGMENTED SO NO NEED TO AUGMENT FURTHER**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3I4WM0UUESQ"
   },
   "source": [
    "# **MODEL BUILDING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QMSdMjyHUKy3"
   },
   "source": [
    "# 1. Load Dataset for Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4727,
     "status": "ok",
     "timestamp": 1735492111434,
     "user": {
      "displayName": "Faisal Yousuf",
      "userId": "02177083131466506578"
     },
     "user_tz": -330
    },
    "id": "btK9qiXFUJqY",
    "outputId": "0ba0f2f0-3a63-4432-d264-c8c909370a05"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Normalization only\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=90,\n",
    "    width_shift_range=0.0,\n",
    "    height_shift_range=0.0,\n",
    "    shear_range=0.0,\n",
    "    zoom_range=0.0,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    rescale=1/255.0,\n",
    "\n",
    "    preprocessing_function=None)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1/255.0)\n",
    "\n",
    "# Load datasets\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    r'C:\\Users\\FAISAL\\Machine_learning\\myproject\\New Plant Diseases Dataset(Augmented)\\New Plant Diseases Dataset(Augmented)\\train',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "valid_generator = val_datagen.flow_from_directory(\n",
    "    r'C:\\Users\\FAISAL\\Machine_learning\\myproject\\New Plant Diseases Dataset(Augmented)\\New Plant Diseases Dataset(Augmented)\\valid',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "train_generator.class_indices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nj5eNywgxpSz"
   },
   "source": [
    "# display some images from training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1RqSVW26B0QzZtYMLaUa9WlgzWK_Yvgw2"
    },
    "executionInfo": {
     "elapsed": 9478,
     "status": "ok",
     "timestamp": 1735492132763,
     "user": {
      "displayName": "Faisal Yousuf",
      "userId": "02177083131466506578"
     },
     "user_tz": -330
    },
    "id": "V_OV-tsuxU2h",
    "outputId": "158399d6-ee38-4226-d493-7ed510b2904f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "classes=list(train_generator.class_indices.keys())\n",
    "plt.figure(figsize=(20,20))\n",
    "for X_batch, y_batch in train_generator:\n",
    "    # create a grid of 3x3 images\n",
    "    for i in range(0,8):\n",
    "        plt.subplot(4,4,i+1)\n",
    "        plt.imshow(X_batch[i])\n",
    "        plt.title(classes[np.where(y_batch[i]==1)[0][0]])   # when y is categorical\n",
    "        # plt.title(classes[int(y_batch[i])])   # when y is binary or sparse\n",
    "        plt.grid(None)\n",
    "    # show the plot\n",
    "    plt.show()\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8bA6m8-UGTVX"
   },
   "source": [
    "# 4. MODEL BUILDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "executionInfo": {
     "elapsed": 803,
     "status": "ok",
     "timestamp": 1735492594907,
     "user": {
      "displayName": "Faisal Yousuf",
      "userId": "02177083131466506578"
     },
     "user_tz": -330
    },
    "id": "axtD8ZXp-fhl",
    "outputId": "f3e35752-78b1-40c7-c0a2-4488ee1260f7"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Convolutional layers\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the output from convolutional layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layers\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))  # Dropout to prevent overfitting\n",
    "model.add(Dense(38, activation='softmax'))  # Output layer with softmax\n",
    "\n",
    "# Compile the model\n",
    "from tensorflow.keras.metrics import Precision\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', Precision()])\n",
    "\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fNht83a9GaUT"
   },
   "source": [
    "# 5. MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define EarlyStopping callback\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)\n",
    "\n",
    "model_checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "model_ReduceLROnPlateau = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4, min_lr=0.000001)\n",
    "\n",
    "callbacks=[early_stopping,model_checkpoint,model_ReduceLROnPlateau]\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "   # steps_per_epoch=(train_generator.samples // train_generator.batch_size),\n",
    "    epochs=16,  # Set a larger number of epochs\n",
    "    validation_data=valid_generator,\n",
    "   # validation_steps=(valid_generator.samples // valid_generator.batch_size),\n",
    "    callbacks=callbacks  # Add early stopping callback\n",
    ")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>Test model on test_data</H1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Load test data using ImageDataGenerator (already set up correctly)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    r'C:\\Users\\FAISAL\\Machine_learning\\myproject\\test',  # Test data directory\n",
    "    target_size=(256, 256),\n",
    "    batch_size=1,  # Use batch_size=1 for individual image prediction\n",
    "    class_mode=None,  # No labels for prediction\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# True labels for your test images (make sure the number of labels matches the number of test images)\n",
    "true_labels = [2, 2, 2, 2, 0, 0, 0, 8, 8, 8, 20, 20, 20, 20, 20, 22, 22, 29, 29, 29, 29, 29, 29, 37, 37, 37, 37, 35, 35, 35, 35, 35, 35]\n",
    "\n",
    "# Predict the classes using the trained model\n",
    "predictions = model.predict(test_generator)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, predicted_classes)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Prepare to display correct and incorrect predictions\n",
    "correct_images = []\n",
    "incorrect_images = []\n",
    "correct_labels = []\n",
    "incorrect_labels = []\n",
    "\n",
    "# Get file paths for test images\n",
    "file_paths = test_generator.filepaths\n",
    "\n",
    "# Loop through each image and compare the true vs predicted labels\n",
    "for i in range(len(true_labels)):\n",
    "    image_name = os.path.basename(file_paths[i])  # Get the image file name\n",
    "    true_label = true_labels[i]\n",
    "    predicted_label = predicted_classes[i]\n",
    "\n",
    "    # If the prediction is correct, add it to the correct list\n",
    "    if true_label == predicted_label:\n",
    "        correct_images.append((image_name, true_label, predicted_label))\n",
    "        correct_labels.append(true_label)\n",
    "    else:\n",
    "        incorrect_images.append((image_name, true_label, predicted_label))\n",
    "        incorrect_labels.append(true_label)\n",
    "\n",
    "# Print Correct Predictions\n",
    "print(\"\\nCorrect Predictions:\")\n",
    "for image_name, true_label, predicted_label in correct_images:\n",
    "    print(f\"Image: {image_name} | True Label: {true_label} | Predicted Label: {predicted_label}\")\n",
    "\n",
    "# Print Incorrect Predictions\n",
    "print(\"\\nIncorrect Predictions:\")\n",
    "for image_name, true_label, predicted_label in incorrect_images:\n",
    "    print(f\"Image: {image_name} | True Label: {true_label} | Predicted Label: {predicted_label}\")\n",
    "\n",
    "# Display a few example images with correct and incorrect predictions\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "def display_images_in_grid(images, titles, max_columns=6):\n",
    "    # Calculate number of rows needed for the grid\n",
    "    num_images = len(images)\n",
    "    num_rows = math.ceil(num_images / max_columns)\n",
    "    \n",
    "    # Create a grid of subplots\n",
    "    fig, axes = plt.subplots(nrows=num_rows, ncols=max_columns, figsize=(max_columns * 3, num_rows * 4))\n",
    "    axes = axes.flatten()  # Flatten the axes array for easy indexing\n",
    "    \n",
    "    for i, (image, title) in enumerate(zip(images, titles)):\n",
    "        ax = axes[i]\n",
    "        ax.imshow(image)\n",
    "        ax.set_title(title, fontsize=8)\n",
    "        ax.axis('off')  # Turn off axis\n",
    "    \n",
    "    # Hide any unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "    \n",
    "    plt.tight_layout()  # Adjust layout to avoid overlap\n",
    "    plt.show()\n",
    "\n",
    "# Collect the correct images and titles (all of them)\n",
    "correct_images_to_show = []\n",
    "correct_titles = []\n",
    "\n",
    "for image_name, true_label, predicted_label in correct_images:  # No slicing here\n",
    "    image_path = os.path.join(r'C:\\Users\\FAISAL\\Machine_learning\\myproject\\test\\test', image_name)\n",
    "    if os.path.exists(image_path):\n",
    "        img = plt.imread(image_path)\n",
    "        correct_images_to_show.append(img)\n",
    "        correct_titles.append(f\"Correct: {image_name} | True: {true_label} | Pred: {predicted_label}\")\n",
    "\n",
    "# Collect the incorrect images and titles (all of them)\n",
    "incorrect_images_to_show = []\n",
    "incorrect_titles = []\n",
    "\n",
    "for image_name, true_label, predicted_label in incorrect_images:  # No slicing here\n",
    "    image_path = os.path.join(r'C:\\Users\\FAISAL\\Machine_learning\\myproject\\test\\test', image_name)\n",
    "    if os.path.exists(image_path):\n",
    "        img = plt.imread(image_path)\n",
    "        incorrect_images_to_show.append(img)\n",
    "        incorrect_titles.append(f\"Incorrect: {image_name} | True: {true_label} | Pred: {predicted_label}\")\n",
    "\n",
    "# Display the correct images in a grid\n",
    "print(\"Displaying Correct Predictions:\")\n",
    "display_images_in_grid(correct_images_to_show, correct_titles, max_columns=6)  # Adjust number of columns as needed\n",
    "\n",
    "# Display the incorrect images in a grid\n",
    "print(\"Displaying Incorrect Predictions:\")\n",
    "display_images_in_grid(incorrect_images_to_show, incorrect_titles, max_columns=6)  # Adjust number of columns as needed\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Prepare to display correct and incorrect predictions\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "# Initialize counters for correct and incorrect predictions\n",
    "correct_counts = defaultdict(int)\n",
    "incorrect_counts = defaultdict(int)\n",
    "\n",
    "# Get file paths for test images\n",
    "file_paths = test_generator.filepaths\n",
    "\n",
    "# Loop through each image and compare the true vs predicted labels\n",
    "for i in range(len(true_labels)):\n",
    "    true_label = true_labels[i]\n",
    "    predicted_label = predicted_classes[i]\n",
    "    \n",
    "    if true_label == predicted_label:\n",
    "        correct_counts[file_paths[i]] += 1  # Track correct predictions by image path\n",
    "    else:\n",
    "        incorrect_counts[file_paths[i]] += 1  # Track incorrect predictions by image path\n",
    "\n",
    "# Create the plot\n",
    "x = np.arange(len(file_paths))  # Number of images\n",
    "width = 0.35  # Bar width\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Get the counts for correct and incorrect predictions\n",
    "correct_values = [correct_counts[file] for file in file_paths]\n",
    "incorrect_values = [incorrect_counts[file] for file in file_paths]\n",
    "\n",
    "# Plotting correct and incorrect bars\n",
    "rects1 = ax.bar(x - width / 2, correct_values, width, label='Correct Predictions')\n",
    "rects2 = ax.bar(x + width / 2, incorrect_values, width, label='Incorrect Predictions')\n",
    "\n",
    "# Add labels, title, and x-axis ticks\n",
    "ax.set_xlabel('Image Names')\n",
    "ax.set_ylabel('Number of Predictions')\n",
    "ax.set_title('Correct vs Incorrect Predictions per Image')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([os.path.basename(file) for file in file_paths], rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "# Adjust layout for better fit\n",
    "fig.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "cm = confusion_matrix(true_labels, predicted_classes, labels=all_labels)\n",
    "\n",
    "# Map labels to class names or indices for visualization\n",
    "class_names = [f\"Class {label}\" for label in all_labels]  # Replace with specific class names if available\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Blues',\n",
    "    xticklabels=class_names,\n",
    "    yticklabels=class_names\n",
    ")\n",
    "\n",
    "plt.title('Confusion Matrix (Including All Predictions)', fontsize=16)\n",
    "plt.xlabel('Predicted Labels', fontsize=12)\n",
    "plt.ylabel('True Labels', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# Additional Analysis: Print incorrect predictions with image names\n",
    "print(\"\\nIncorrect Predictions:\")\n",
    "file_paths = test_generator.filepaths  # File paths for test images\n",
    "\n",
    "for i, (true, pred) in enumerate(zip(true_labels, predicted_classes)):\n",
    "    if true != pred:\n",
    "        image_name = os.path.basename(file_paths[i])  # Extract image file name\n",
    "        print(f\"Image: {image_name} | True Label: {true} | Predicted Label: {pred}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model (architecture + weights) in SavedModel format\n",
    "model.save('my_full_model_saved')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
