{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Decision Tree From Scratch (Lab 6)\nThis notebook contains full step\u2011by\u2011step implementation."]}, {"cell_type": "code", "metadata": {}, "source": ["import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_moons\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.tree import DecisionTreeClassifier\nfrom math import log2\n"]}, {"cell_type": "code", "metadata": {}, "source": ["# Dataset\nX, y = make_moons(n_samples=400, noise=0.25, random_state=42)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"]}, {"cell_type": "code", "metadata": {}, "source": ["def gini_impurity(y):\n    if len(y)==0: return 0\n    _, c = np.unique(y, return_counts=True)\n    p = c/len(y)\n    return 1 - np.sum(p**2)\n\ndef entropy(y):\n    if len(y)==0: return 0\n    _, c = np.unique(y, return_counts=True)\n    p = c/len(y)\n    return -np.sum(p*np.log2(p))\n"]}, {"cell_type": "code", "metadata": {}, "source": ["def information_gain(y, y_l, y_r, criterion=\"gini\"):\n    imp = gini_impurity if criterion==\"gini\" else entropy\n    H = imp(y)\n    n=len(y)\n    return H - (len(y_l)/n)*imp(y_l) - (len(y_r)/n)*imp(y_r)\n"]}, {"cell_type": "code", "metadata": {}, "source": ["class TreeNode:\n    def __init__(self,feature_index=None,threshold=None,left=None,right=None,value=None):\n        self.feature_index=feature_index\n        self.threshold=threshold\n        self.left=left\n        self.right=right\n        self.value=value\n    def is_leaf(self): return self.value is not None\n"]}, {"cell_type": "code", "metadata": {}, "source": ["class MyDecisionTreeClassifier:\n    def __init__(self,max_depth=None,min_samples_leaf=1,criterion=\"gini\"):\n        self.max_depth=max_depth\n        self.min_samples_leaf=min_samples_leaf\n        self.criterion=criterion\n\n    def fit(self,X,y):\n        self.root=self._build_tree(X,y,0)\n\n    def _majority(self,y):\n        vals,c=np.unique(y,return_counts=True)\n        return vals[np.argmax(c)]\n\n    def _build_tree(self,X,y,depth):\n        if (self.max_depth and depth>=self.max_depth) or len(np.unique(y))==1 or len(y)<=self.min_samples_leaf:\n            return TreeNode(value=self._majority(y))\n\n        best_gain=-1; best_feat=None; best_thr=None\n        for f in range(X.shape[1]):\n            for t in np.unique(X[:,f]):\n                left=X[:,f]<=t\n                y_l, y_r = y[left], y[~left]\n                gain=information_gain(y,y_l,y_r,self.criterion)\n                if gain>best_gain:\n                    best_gain=gain; best_feat=f; best_thr=t\n        if best_gain<=0:\n            return TreeNode(value=self._majority(y))\n\n        left = X[:,best_feat]<=best_thr\n        lnode=self._build_tree(X[left], y[left], depth+1)\n        rnode=self._build_tree(X[~left], y[~left], depth+1)\n        return TreeNode(best_feat,best_thr,lnode,rnode)\n\n    def _predict_one(self,x,node):\n        if node.is_leaf(): return node.value\n        return self._predict_one(x,node.left if x[node.feature_index]<=node.threshold else node.right)\n\n    def predict(self,X): return np.array([self._predict_one(x,self.root) for x in X])\n"]}, {"cell_type": "code", "metadata": {}, "source": ["tree_gini = MyDecisionTreeClassifier(max_depth=4, criterion=\"gini\")\ntree_gini.fit(X_train, y_train)\npred = tree_gini.predict(X_test)\naccuracy_score(y_test,pred), confusion_matrix(y_test,pred)\n"]}], "metadata": {"kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}}, "nbformat": 4, "nbformat_minor": 2}